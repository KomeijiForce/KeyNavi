{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94478bb-d1ba-42f5-b1b0-6579cd455df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from kmeans_pytorch import kmeans\n",
    "import torch\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import openai\n",
    "from constant import openai_key\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "openai.api_key = openai_key\n",
    "model_engine = \"gpt-4o\" \n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de6ac76-24f2-44b2-86b4-df5b34665bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "generator = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "generator.eval()\n",
    "generator = generator.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb55af3-7ee1-4bef-b8ca-7984c7302e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_cache = {}\n",
    "\n",
    "def probe(seq):\n",
    "    if seq in probe_cache:\n",
    "        return probe_cache[seq]\n",
    "        \n",
    "    for _ in range(64):\n",
    "        logits = generator(**tokenizer(seq, return_tensors=\"pt\").to(\"cuda\")).logits[0, -1]\n",
    "        probs = logits.softmax(-1)\n",
    "        idx = logits.argsort(descending=True)[0]\n",
    "        next_token = tokenizer.decode(idx)\n",
    "        seq += next_token\n",
    "        if \"\\\"\" in next_token:\n",
    "            break\n",
    "\n",
    "    if len(re.findall(\"\\\"(.*)?\\\"\", seq)) > 0:\n",
    "        ans = re.findall(\"\\\"(.*)?\\\"\", seq)[-1]\n",
    "    else:\n",
    "        ans = \"nothing\"\n",
    "        \n",
    "    probe_cache[seq] = ans\n",
    "\n",
    "    return ans\n",
    "\n",
    "def score(answer, instruction):\n",
    "\n",
    "    if answer in cache:\n",
    "        return cache[answer]\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "    model=model_engine,\n",
    "    temperature=0.0,\n",
    "    messages=[{\"role\": \"user\", \"content\": f'''{instruction}\\n\\nIs \"{answer}\" considered as among the correct answers? Answer only \"Yes\" or \"No\".'''}],\n",
    "    ).choices[0]['message'][\"content\"]\n",
    "    sleep(1.0)\n",
    "    if \"yes\" in response.lower():\n",
    "        cache[answer] = 1\n",
    "        return 1\n",
    "    else:\n",
    "        cache[answer] = 0\n",
    "        return 0\n",
    "\n",
    "def verbalize_escape(escape_list):\n",
    "    return \"\".join(f\"{idx+1}. \\\"{escape}\\\"\\n\" for idx, escape in enumerate(escape_list)) + f\"{1+len(escape_list)}. \\\"\"\n",
    "\n",
    "def mapk(res, k=10):\n",
    "    \n",
    "    return np.mean([np.mean(res[:i+1]) for i in range(k)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ae1975-9f54-405d-8a6c-f40fd58f66a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.eval()\n",
    "N = 100\n",
    "K = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea51c16e-b50e-44b7-9bf3-68530d1025c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"llama3_8b\"\n",
    "cluster_ids_x = torch.load(f'cluster/cluster_ids_x.{model_name}.pt').to(\"cuda\")\n",
    "cluster_centers = torch.load(f'cluster/cluster_centers.{model_name}.pt').to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0a8257-b62c-486a-a3a0-6c9d658d1557",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def probe_exp(instruction, escape_list, N, K, reg):\n",
    "\n",
    "    main_cluster_ids = []\n",
    "    main_cluster_golds = []\n",
    "    main_cluster_ranks = []\n",
    "    other_cluster_golds = []\n",
    "    other_cluster_ranks = []\n",
    "    golds = []\n",
    "    \n",
    "    res = 0\n",
    "    \n",
    "    init_prompt = f'''{instruction}\n",
    "\n",
    "Answer:\n",
    "{verbalize_escape(escape_list)}'''\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        prompt = f'''{instruction}\n",
    "\n",
    "Answer:\n",
    "{verbalize_escape(escape_list)}'''\n",
    "    \n",
    "        items = generator(**tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\"), output_hidden_states=True)\n",
    "        initial_state = items.hidden_states[-1][0, -1]\n",
    "        lm_head_weight = generator.lm_head.weight\n",
    "        # lm_head_weight = torch.nn.functional.normalize(lm_head_weight)\n",
    "        logits = (initial_state.unsqueeze(0) * lm_head_weight).sum(-1)\n",
    "        probs = logits.softmax(-1)\n",
    "        ids = logits.argsort(descending=True)\n",
    "        next_tokens = [tokenizer.decode(idx) for idx in ids]\n",
    "        X = generator.lm_head.weight[ids]\n",
    "    \n",
    "        cnt = 0\n",
    "    \n",
    "        bar = tqdm(zip(X, ids, next_tokens), total=N)\n",
    "        \n",
    "        for x, idx, next_token in bar:\n",
    "            cnt += 1\n",
    "            idx = idx.item()\n",
    "            cluster_idx = cluster_ids_x[idx].item()\n",
    "            if reg:\n",
    "                entity = probe(init_prompt+next_token)\n",
    "            else:\n",
    "                entity = probe(prompt+next_token)\n",
    "            gold = score(entity, instruction)\n",
    "            golds.append(gold)\n",
    "            escape_list.append(entity)\n",
    "    \n",
    "            if cnt <= K:\n",
    "                main_cluster_ids.append(cluster_idx)\n",
    "            else:\n",
    "                if cluster_idx in main_cluster_ids:\n",
    "                    main_cluster_golds.append(gold)\n",
    "                    main_cluster_ranks.append(cnt)\n",
    "                else:\n",
    "                    other_cluster_golds.append(gold)\n",
    "                    other_cluster_ranks.append(cnt)\n",
    "    \n",
    "            if len(main_cluster_golds) > 0 and len(other_cluster_golds) > 0:\n",
    "                avg_main = np.mean(main_cluster_golds)\n",
    "                avg_other = np.mean(other_cluster_golds)\n",
    "                avg_main_rank = np.mean(main_cluster_ranks)\n",
    "                avg_other_rank = np.mean(other_cluster_ranks)\n",
    "                avg_main_prop = len(main_cluster_golds)/(len(main_cluster_golds) + len(other_cluster_golds))\n",
    "                avg_other_prop = len(other_cluster_golds)/(len(main_cluster_golds) + len(other_cluster_golds))\n",
    "                avg_top = np.mean(golds[:K])\n",
    "                bar.set_description(f\"G Main = {avg_main*100:.4}, G Other = {avg_other*100:.4}, R Main = {avg_main_rank:.4}, R Other  = {avg_other_rank:.4}, P Main = {avg_main_prop:.4}, P Other  = {avg_other_prop:.4}\")\n",
    "                \n",
    "            if cnt == N:\n",
    "                break\n",
    "                \n",
    "    return avg_main, avg_other, avg_main_rank, avg_other_rank, avg_main_prop, avg_other_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848d4125-732b-4085-af71-6f781b088094",
   "metadata": {},
   "outputs": [],
   "source": [
    "RES = {}\n",
    "\n",
    "instruction_escape_list = [\n",
    "    (\"Please show me some sports leagues.\", []),\n",
    "    (\"Please show me some basketball sports leagues.\", []),\n",
    "    (\"Please show me some baseball sports leagues.\", []),\n",
    "    (\"Please show me some USA sports leagues.\", []), \n",
    "    (\"Please show me some European sports leagues.\", []),\n",
    "]\n",
    "\n",
    "for instruction_escape in instruction_escape_list:\n",
    "\n",
    "    instruction, escape_list = instruction_escape\n",
    "    \n",
    "    cache = {}\n",
    "    reg=True\n",
    "    \n",
    "    avg_main, avg_other, avg_main_rank, avg_other_rank, avg_main_prop, avg_other_prop = probe_exp(instruction, escape_list, N, K, reg)\n",
    "    res = {\"avg_main\": avg_main, \n",
    "    \"avg_other\": avg_other, \n",
    "    \"avg_main_rank\": avg_main_rank, \n",
    "    \"avg_other_rank\": avg_other_rank,\n",
    "    \"avg_main_prop\": avg_main_prop, \n",
    "    \"avg_other_prop\": avg_other_prop}\n",
    "\n",
    "    RES[instruction] = res\n",
    "\n",
    "print(RES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e5b43d-1b26-4e7b-ab92-953968bc3636",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
